{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEGO Nowości Scraper\n",
    "\n",
    "Ten notebook scrapuje nowości ze strony LEGO Polska (lego.com/pl-pl).\n",
    "\n",
    "**Funkcjonalności:**\n",
    "- Instalacja ChromeDriver dla Google Colab\n",
    "- Scraping produktów z sekcji \"Nowości\"\n",
    "- Ekstrakcja: nazwa, cena, liczba elementów, wiek, ocena, dostępność\n",
    "- Zapis do DataFrame i CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Instalacja i konfiguracja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_chromedriver():\n",
    "    \"\"\"Instaluje ChromeDriver na Google Colab.\"\"\"\n",
    "    print(\"Instalowanie chromedriver...\")\n",
    "    try:\n",
    "        subprocess.check_output([\"apt\", \"update\"], stderr=subprocess.STDOUT)\n",
    "        subprocess.check_output([\"apt-get\", \"install\", \"-y\", \"chromium-chromedriver\"], stderr=subprocess.STDOUT)\n",
    "        subprocess.check_output([\"cp\", \"/usr/lib/chromium-browser/chromedriver\", \"/usr/bin\"], stderr=subprocess.STDOUT)\n",
    "        print(\"Chromedriver zainstalowany pomyslnie.\")\n",
    "        return True\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Blad podczas instalacji chromedriver: {e}\")\n",
    "        return False\n",
    "\n",
    "# Sprawdz czy jestesmy na Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"Wykryto Google Colab\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"Lokalne srodowisko\")\n",
    "\n",
    "if IN_COLAB:\n",
    "    install_chromedriver()\n",
    "    !pip install -q selenium webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importy\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Konfiguracja przegladarki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_driver():\n",
    "    \"\"\"Tworzy instancje Chrome WebDriver.\"\"\"\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "    chrome_options.add_argument(\"--window-size=1920,1080\")\n",
    "    chrome_options.add_argument(\"--lang=pl-PL\")\n",
    "    chrome_options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\")\n",
    "    \n",
    "    if IN_COLAB:\n",
    "        driver = webdriver.Chrome(options=chrome_options)\n",
    "    else:\n",
    "        from webdriver_manager.chrome import ChromeDriverManager\n",
    "        service = Service(ChromeDriverManager().install())\n",
    "        driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "    \n",
    "    return driver\n",
    "\n",
    "print(\"Funkcja create_driver() gotowa.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Funkcje do scrapowania"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accept_cookies(driver):\n",
    "    \"\"\"Akceptuje cookies na stronie LEGO.\"\"\"\n",
    "    try:\n",
    "        cookie_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.ID, \"age-gate-grown-up-cta\"))\n",
    "        )\n",
    "        cookie_button.click()\n",
    "        time.sleep(1)\n",
    "    except TimeoutException:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        accept_btn = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.CSS_SELECTOR, \"button[data-test='cookie-accept-all]\"))\n",
    "        )\n",
    "        accept_btn.click()\n",
    "        time.sleep(1)\n",
    "    except TimeoutException:\n",
    "        pass\n",
    "\n",
    "def scroll_page(driver, scrolls=5, delay=2):\n",
    "    \"\"\"Przewija strone aby zaladowac wiecej produktow.\"\"\"\n",
    "    for i in range(scrolls):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(delay)\n",
    "        print(f\"Przewinieto {i+1}/{scrolls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_product_data(product_element):\n",
    "    \"\"\"Ekstrahuje dane z pojedynczego elementu produktu.\"\"\"\n",
    "    data = {\n",
    "        'nazwa': None,\n",
    "        'cena': None,\n",
    "        'cena_numeryczna': None,\n",
    "        'liczba_elementow': None,\n",
    "        'wiek': None,\n",
    "        'ocena': None,\n",
    "        'dostepnosc': None,\n",
    "        'url': None,\n",
    "        'obrazek_url': None,\n",
    "        'nowosc': False\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Nazwa produktu\n",
    "        try:\n",
    "            name_elem = product_element.find_element(By.CSS_SELECTOR, \"span[data-test='product-leaf-title'], h3, .ProductTitlestyles__ProductTitleText\")\n",
    "            data['nazwa'] = name_elem.text.strip()\n",
    "        except NoSuchElementException:\n",
    "            try:\n",
    "                name_elem = product_element.find_element(By.CSS_SELECTOR, \"a[data-test='product-leaf-title-link']\")\n",
    "                data['nazwa'] = name_elem.text.strip()\n",
    "            except NoSuchElementException:\n",
    "                pass\n",
    "        \n",
    "        # Cena\n",
    "        try:\n",
    "            price_elem = product_element.find_element(By.CSS_SELECTOR, \"span[data-test='product-leaf-price'], .ProductPricestyles__PriceText\")\n",
    "            price_text = price_elem.text.strip()\n",
    "            data['cena'] = price_text\n",
    "            # Ekstrakcja numerycznej wartosci ceny\n",
    "            price_match = re.search(r'([\\d\\s,]+)', price_text.replace(' ', ''))\n",
    "            if price_match:\n",
    "                price_num = price_match.group(1).replace(',', '.').replace(' ', '')\n",
    "                try:\n",
    "                    data['cena_numeryczna'] = float(price_num)\n",
    "                except ValueError:\n",
    "                    pass\n",
    "        except NoSuchElementException:\n",
    "            pass\n",
    "        \n",
    "        # Liczba elementow\n",
    "        try:\n",
    "            pieces_elem = product_element.find_element(By.CSS_SELECTOR, \"span[data-test='product-leaf-piece-count-label']\")\n",
    "            pieces_text = pieces_elem.text.strip()\n",
    "            pieces_match = re.search(r'(\\d+)', pieces_text)\n",
    "            if pieces_match:\n",
    "                data['liczba_elementow'] = int(pieces_match.group(1))\n",
    "        except NoSuchElementException:\n",
    "            pass\n",
    "        \n",
    "        # Wiek\n",
    "        try:\n",
    "            age_elem = product_element.find_element(By.CSS_SELECTOR, \"span[data-test='product-leaf-age-range-label']\")\n",
    "            data['wiek'] = age_elem.text.strip()\n",
    "        except NoSuchElementException:\n",
    "            pass\n",
    "        \n",
    "        # Ocena\n",
    "        try:\n",
    "            rating_elem = product_element.find_element(By.CSS_SELECTOR, \"div[data-test='product-leaf-rating'] span, .Ratingstyles__RatingValue\")\n",
    "            rating_text = rating_elem.text.strip()\n",
    "            rating_match = re.search(r'([\\d.,]+)', rating_text)\n",
    "            if rating_match:\n",
    "                data['ocena'] = float(rating_match.group(1).replace(',', '.'))\n",
    "        except NoSuchElementException:\n",
    "            pass\n",
    "        \n",
    "        # Dostepnosc (przycisk)\n",
    "        try:\n",
    "            button_elem = product_element.find_element(By.CSS_SELECTOR, \"button[data-test='product-leaf-cta'], button\")\n",
    "            button_text = button_elem.text.strip().lower()\n",
    "            if 'dodaj' in button_text or 'koszyk' in button_text:\n",
    "                data['dostepnosc'] = 'Dostepny'\n",
    "            elif 'niedostepn' in button_text:\n",
    "                data['dostepnosc'] = 'Niedostepny'\n",
    "            elif 'wkrotce' in button_text:\n",
    "                data['dostepnosc'] = 'Wkrotce dostepne'\n",
    "            elif 'przedsprzeda' in button_text:\n",
    "                data['dostepnosc'] = 'Przedsprzedaz'\n",
    "            else:\n",
    "                data['dostepnosc'] = button_text\n",
    "        except NoSuchElementException:\n",
    "            pass\n",
    "        \n",
    "        # URL produktu\n",
    "        try:\n",
    "            link_elem = product_element.find_element(By.CSS_SELECTOR, \"a[data-test='product-leaf-title-link'], a[href*='/product/']\")\n",
    "            data['url'] = link_elem.get_attribute('href')\n",
    "        except NoSuchElementException:\n",
    "            pass\n",
    "        \n",
    "        # Obrazek\n",
    "        try:\n",
    "            img_elem = product_element.find_element(By.CSS_SELECTOR, \"img[data-test='product-leaf-image'], img\")\n",
    "            data['obrazek_url'] = img_elem.get_attribute('src')\n",
    "        except NoSuchElementException:\n",
    "            pass\n",
    "        \n",
    "        # Sprawdz czy jest \"Nowosc\"\n",
    "        try:\n",
    "            badge_elem = product_element.find_element(By.CSS_SELECTOR, \"span[data-test='product-leaf-badges-new'], .Badge\")\n",
    "            if 'nowo' in badge_elem.text.lower():\n",
    "                data['nowosc'] = True\n",
    "        except NoSuchElementException:\n",
    "            data['nowosc'] = True  # Na stronie nowosci wszystkie produkty sa \"nowosciami\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Blad podczas ekstrakcji danych: {e}\")\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_lego_nowosci(url=\"https://www.lego.com/pl-pl/categories/new-sets-and-products\", max_scrolls=10):\n",
    "    \"\"\"Glowna funkcja scrapujaca nowosci LEGO.\"\"\"\n",
    "    print(f\"Rozpoczynam scrapowanie: {url}\")\n",
    "    \n",
    "    driver = create_driver()\n",
    "    products = []\n",
    "    \n",
    "    try:\n",
    "        driver.get(url)\n",
    "        print(\"Strona zaladowana\")\n",
    "        time.sleep(3)\n",
    "        \n",
    "        # Akceptuj cookies\n",
    "        accept_cookies(driver)\n",
    "        \n",
    "        # Przewin strone aby zaladowac wiecej produktow\n",
    "        scroll_page(driver, scrolls=max_scrolls, delay=2)\n",
    "        \n",
    "        # Znajdz wszystkie produkty\n",
    "        product_selectors = [\n",
    "            \"li[data-test='product-leaf']\",\n",
    "            \"article[data-test='product-leaf']\",\n",
    "            \".ProductLeafstyles__ProductLeafWrapper\",\n",
    "            \"[data-test='product-item']\"\n",
    "        ]\n",
    "        \n",
    "        product_elements = []\n",
    "        for selector in product_selectors:\n",
    "            elements = driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "            if elements:\n",
    "                product_elements = elements\n",
    "                print(f\"Znaleziono {len(elements)} produktow uzywajac selektora: {selector}\")\n",
    "                break\n",
    "        \n",
    "        if not product_elements:\n",
    "            print(\"Nie znaleziono produktow. Probuje alternatywnej metody...\")\n",
    "            product_elements = driver.find_elements(By.CSS_SELECTOR, \"[class*='ProductLeaf']\")\n",
    "            print(f\"Znaleziono {len(product_elements)} produktow\")\n",
    "        \n",
    "        # Ekstrakcja danych z kazdego produktu\n",
    "        for i, product_elem in enumerate(product_elements):\n",
    "            print(f\"Przetwarzanie produktu {i+1}/{len(product_elements)}\")\n",
    "            product_data = extract_product_data(product_elem)\n",
    "            if product_data['nazwa']:  # Dodaj tylko jesli ma nazwe\n",
    "                products.append(product_data)\n",
    "        \n",
    "        print(f\"\\nZakończono. Pobrano {len(products)} produktow.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Blad podczas scrapowania: {e}\")\n",
    "    finally:\n",
    "        driver.quit()\n",
    "    \n",
    "    return products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Uruchomienie scrapera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapuj nowosci LEGO\n",
    "products = scrape_lego_nowosci(max_scrolls=5)\n",
    "print(f\"\\nPobrano {len(products)} produktow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utworz DataFrame\n",
    "df = pd.DataFrame(products)\n",
    "\n",
    "# Dodaj timestamp\n",
    "df['data_scrapowania'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Wyswietl wyniki\n",
    "print(f\"Liczba produktow: {len(df)}\")\n",
    "print(f\"\\nKolumny: {list(df.columns)}\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statystyki\n",
    "print(\"=== STATYSTYKI ===\")\n",
    "print(f\"Liczba produktow: {len(df)}\")\n",
    "\n",
    "if 'cena_numeryczna' in df.columns and df['cena_numeryczna'].notna().any():\n",
    "    print(f\"\\nCeny:\")\n",
    "    print(f\"  Min: {df['cena_numeryczna'].min():.2f} zl\")\n",
    "    print(f\"  Max: {df['cena_numeryczna'].max():.2f} zl\")\n",
    "    print(f\"  Srednia: {df['cena_numeryczna'].mean():.2f} zl\")\n",
    "\n",
    "if 'liczba_elementow' in df.columns and df['liczba_elementow'].notna().any():\n",
    "    print(f\"\\nLiczba elementow:\")\n",
    "    print(f\"  Min: {df['liczba_elementow'].min()}\")\n",
    "    print(f\"  Max: {df['liczba_elementow'].max()}\")\n",
    "    print(f\"  Srednia: {df['liczba_elementow'].mean():.0f}\")\n",
    "\n",
    "if 'dostepnosc' in df.columns:\n",
    "    print(f\"\\nDostepnosc:\")\n",
    "    print(df['dostepnosc'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Zapis do pliku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zapis do CSV\n",
    "filename = f\"lego_nowosci_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    "df.to_csv(filename, index=False, encoding='utf-8-sig')\n",
    "print(f\"Zapisano do pliku: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dla Google Colab - pobierz plik\n",
    "if IN_COLAB:\n",
    "    from google.colab import files\n",
    "    files.download(filename)\n",
    "    print(\"Plik zostal pobrany.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Wizualizacja (opcjonalnie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Rozklad cen\n",
    "if 'cena_numeryczna' in df.columns and df['cena_numeryczna'].notna().any():\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    df['cena_numeryczna'].hist(bins=20, edgecolor='black')\n",
    "    plt.xlabel('Cena (zl)')\n",
    "    plt.ylabel('Liczba produktow')\n",
    "    plt.title('Rozklad cen nowosci LEGO')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dostepnosc produktow\n",
    "if 'dostepnosc' in df.columns and df['dostepnosc'].notna().any():\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    df['dostepnosc'].value_counts().plot(kind='pie', autopct='%1.1f%%')\n",
    "    plt.title('Dostepnosc produktow')\n",
    "    plt.ylabel('')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
